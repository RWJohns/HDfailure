{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here I will take the key features from my data set and run them through weighted classificaton models, current models are Random Forest and Logit\n",
    "\n",
    "due to class imbalance and non-linear features my models are currently correctly identifying approx 10- 50% of the failed hard drives and mis attributing approx 5 - 25% of the working drives as broken. I will implement non-linear feature treatment and svm to address this in the coming days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, ensemble, linear_model, neighbors, naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, \n",
    "                              AdaBoostClassifier, BaggingRegressor)\n",
    "from sklearn import linear_model, svm, metrics, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"2016_pickle_norm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1013362\n",
       "1      62707\n",
       "Name: failure, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.failure.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>model</th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>failure</th>\n",
       "      <th>smart_187_normalized</th>\n",
       "      <th>smart_188_normalized</th>\n",
       "      <th>smart_189_normalized</th>\n",
       "      <th>smart_192_normalized</th>\n",
       "      <th>smart_197_normalized</th>\n",
       "      <th>smart_198_normalized</th>\n",
       "      <th>smart_242_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>W300K1XB</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Z300H1WJ</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Z304JL7B</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Z302BVHP</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>S300Z5BS</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date serial_number        model  capacity_bytes  failure  \\\n",
       "0  2016-01-01      W300K1XB  ST4000DM000   4000787030016        0   \n",
       "1  2016-01-01      Z300H1WJ  ST4000DM000   4000787030016        0   \n",
       "2  2016-01-01      Z304JL7B  ST4000DM000   4000787030016        0   \n",
       "3  2016-01-01      Z302BVHP  ST4000DM000   4000787030016        0   \n",
       "4  2016-01-01      S300Z5BS  ST4000DM000   4000787030016        0   \n",
       "\n",
       "   smart_187_normalized  smart_188_normalized  smart_189_normalized  \\\n",
       "0                 100.0                 100.0                  96.0   \n",
       "1                 100.0                 100.0                  97.0   \n",
       "2                 100.0                 100.0                 100.0   \n",
       "3                 100.0                 100.0                 100.0   \n",
       "4                 100.0                 100.0                 100.0   \n",
       "\n",
       "   smart_192_normalized  smart_197_normalized  smart_198_normalized  \\\n",
       "0                 100.0                 100.0                 100.0   \n",
       "1                 100.0                 100.0                 100.0   \n",
       "2                 100.0                 100.0                 100.0   \n",
       "3                 100.0                 100.0                 100.0   \n",
       "4                 100.0                 100.0                 100.0   \n",
       "\n",
       "   smart_242_normalized  \n",
       "0                 100.0  \n",
       "1                 100.0  \n",
       "2                 100.0  \n",
       "3                 100.0  \n",
       "4                 100.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                    1076069\n",
       "serial_number           1076069\n",
       "model                   1076069\n",
       "capacity_bytes          1076069\n",
       "failure                 1076069\n",
       "smart_187_normalized    1076069\n",
       "smart_188_normalized    1076069\n",
       "smart_189_normalized    1076069\n",
       "smart_192_normalized    1076069\n",
       "smart_197_normalized    1076069\n",
       "smart_198_normalized    1076069\n",
       "smart_242_normalized    1076069\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,X= df['failure'],df.drop(['failure','serial_number','model','capacity_bytes','date'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_testval, y_train, y_testval = model_selection.train_test_split(X, y, test_size=.5, stratify=y)\n",
    "\n",
    "x_val, x_test, y_val, y_test = model_selection.train_test_split(x_testval, y_testval, test_size=.5, stratify=y_testval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269018, 7)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = preprocessing.MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538034 269017 269018\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(x_val), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2,random_state=13)\n",
    "\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(model):\n",
    "  \n",
    "    y_pred = model.predict(x_val)\n",
    "\n",
    "    print(metrics.classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    253340\n",
      "           1       0.33      0.10      0.15     15677\n",
      "\n",
      "    accuracy                           0.94    269017\n",
      "   macro avg       0.64      0.54      0.56    269017\n",
      "weighted avg       0.91      0.94      0.92    269017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logit=linear_model.LogisticRegression(C = 0.1,class_weight=\"balanced\", solver='lbfgs')\n",
    "logit=linear_model.LogisticRegression(C = 0.1,class_weight=class_weights, solver='lbfgs')\n",
    "logit.fit(x_train, y_train)\n",
    "\n",
    "print_metrics(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {\n",
    "      0: 1,\n",
    "      1: 13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88    253340\n",
      "           1       0.12      0.42      0.19     15677\n",
      "\n",
      "    accuracy                           0.79    269017\n",
      "   macro avg       0.54      0.62      0.53    269017\n",
      "weighted avg       0.91      0.79      0.84    269017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RandomForest_weights = RandomForestClassifier(class_weight=class_weights,n_estimators=200)\n",
    "RandomForest_weights.fit(x_train, y_train)\n",
    "\n",
    "print_metrics(RandomForest_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit=linear_model.LogisticRegression(C = 0.9,class_weight=class_weights, solver='lbfgs')\n",
    "#scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler.fit(X_train)\n",
    "#X_train_scale=scaler.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.9, class_weight={0: 1, 1: 12}, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9302553370233108"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[248689,   4652],\n",
       "       [ 14163,   1514]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, logit.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(class_weight=class_weights,n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={0: 1, 1: 13},\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=200, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7851604173713929"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[204535,  48806],\n",
       "       [  9231,   6446]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, randomforest.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
